{
    "language": "eng",
    "contributors": [
        {
            "name": "Nikita Lukianets",
            "affiliation": "Open Ethics Initiative"
        }
    ],
    "base-url": "https://openethics.ia/taxonomy/",
    "license": "CC-BY-4.0", 
    "taxonomy": [
        {
            "language": "eng",
            "term": "Artificial intelligence",
            "definition": "Artificial intelligence (AI) is a computer-based system that makes it possible for a machine to learn from data, adjust to new inputs, and perform tasks commonly associated with human intelligence. AI systems are designed to operate with varying degrees of autonomy and infer outputs from the inputs they receive. Today AI is properly known as “narrow AI” (or “weak AI”), as it is designed to perform a narrow task (e.g. recognize objects, classify images, recommend products, generate content, conduct goal-oriented conversations).",
            "metaphor": "",
            "updated": "2025-10-05"
        },
        {
            "language": "eng",
            "term": "Inference",
            "definition": "Inference is the process by which a trained AI model processes new data and generates results such as predictions, classifications, or recommendations based on patterns it learned during training. Unlike deterministic logic in traditional software, AI systems rely on these learned patterns rather than fixed rules.",
            "metaphor": "",
            "updated": "2025-10-05"
        },
        {
            "language": "eng",
            "term": "Disclosure",
            "definition": "Disclosure (ethics disclosure, or self-disclosure) describes in a standardized way how the autonomous system was built and how it is supposed to work. Disclosures contain information about the data collection, data processing, and decision-making practices of a digital product and are voluntarily provided by the product’s vendor (an individual developer or an organization).",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Disclosure Validation",
            "definition": "A sequence of automated software-based checks to control validity and security elements in the Disclosure. Disclosure Validation is important to allow the check whether a presented Disclosure was actually issued and issued by the valid Disclosure Identity Provider.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Disclosure Verification",
            "definition": "A procedure to control the correspondence of the elements in the Disclosure and the actual data processing and data collection practices of the product. Disclosure Verification is similar to certification procedures to check whether what was disclosed is true, and to elevate the level of trust to the product and product’s vendor.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Disclosure Identity Provider",
            "definition": "The automated Disclosure processing is enabled by requests to both the Open Ethics Disclosure database powered by Disclosure Identity Providers (DIP) and the product’s Disclosure file, stored in the predefined location of the product’s website, following OETP specification. DIP serves as a service point to generate and retrieve generated disclosures.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Transparency",
            "definition": "Transparency refers to the openness (Ex-ante) of a system or process. In the context of AI applications, it involves revealing the typical decision-making process clearly, setting reasonable expectations about the nature and quality of the output. This includes providing insight into the architectural aspects of systems utilizing AI components, their training datasets, as well as key decisions and boundaries set by engineers. When discussing the property of systems, such as how transparent they are, the term Transparency is used. In contrast, the term Explainability is employed when describing the clarity of the output of AI systems, such as how understandable the results are.",
            "updated": "2023-10-09"
        },
        {
            "language": "eng",
            "term": "Explainability",
            "definition": "Explainability is the capability to offer understandable explanations of how a model or algorithm reaches a specific decision or prediction (Ex-post). It is vital for enhancement, fostering trust, and ensuring the responsible use of AI. To avoid confusion, Transparency is used in the context of system properties, while Explainability is used when characterizing the clarity of AI-generated results, emphasizing how interpretable the outcomes are.",
            "updated": "2023-10-09"
        },
        {
            "language": "eng",
            "term": "Open Ethics Transparency Protocol",
            "definition": "Open Ethics Transparency Protocol (OETP) is a protocol for product owners to generate, host, and verify a machine-readable disclosure for their AI solutions in a standardized and explicit way, without compromising IP or security. The scope of the Protocol covers Disclosures of “ethical postures” for systems such as Software as a Service (SaaS) Applications, Software Applications, Software Components, Application Programming Interfaces (API), Automated Decision-Making (ADM) systems, and systems using Artificial Intelligence (AI). OETP aims to bring more transparent, predictable, and safe environments for the end-users.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Training Data",
            "definition": "The training data is an initial set of data items (examples) used to train an AI model to produce results. Typically, in AI model development, training sets make up the majority of the total data available for model development. The allocation ratio between Training, Test, and Validation is usually around 60%:20%:20%.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Data Labelling",
            "definition": "In supervised machine learning, a model is trained using a labeled training data set. Labeling (or tagging, annotation) procedure typically involves human Labeler to augment each item of unlabeled data with meaningful tags (or labels) that are informative. For example, labels might indicate whether a photo contains a dog or a cat, which words were uttered in an audio recording, what type of action is being performed in a video, what the topic of a news article is, what the overall sentiment of a tweet is, whether the dot in an x-ray is a tumor, etc.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Labeler",
            "definition": "In Machine Learning, Labeler is an individual typically involved in the construction of the Training Data sets by assigning labels to every data item. Labelers use their human knowledge and experience to assign labels, which could result in biased labeling results and therefore in biased predictions by a machine learning model.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Testing Data",
            "definition": "The testing data set is used to provide an unbiased evaluation of a final model fit on the training dataset. After a model has been processed by using the training data set, you test the model by making predictions against the test data set.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Validation Data",
            "definition": "A validation data set is a set of data used to train AI to find and optimize the best model to solve a given problem. Validation sets are also known as dev sets.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Autonomy",
            "definition": "Autonomy in the context of AI and decision-making refers to the ability of an artificial intelligence system to make decisions or take actions without direct human intervention or guidance. However, the level of autonomy can vary, and in many cases, there may be a balance between autonomous decision-making and human oversight to ensure the ethical, safe, and responsible use of AI.",
            "metaphor": "",
            "updated": "2024-02-27"
        },
        {
            "language": "eng",
            "term": "Oversight",
            "definition": "Oversight in the context of AI and decision-making refers to the act of monitoring, supervising, and managing artificial intelligence systems to ensure they operate within established guidelines, ethical standards, and legal frameworks. It often includes mechanisms for human intervention when necessary, especially in critical or complex situations where the AI system may struggle or where human judgment is deemed essential. Effective oversight may involve continuous monitoring, regular audits, and the implementation of feedback loops that allow human operators to review and adjust the behavior of AI systems.",
            "metaphor": "",
            "updated": "2024-02-28"
        },
        {
            "language": "eng",
            "term": "Operator",
            "definition": "An Operator is an individual (natural person) designated to start, control the operation, and stop an autonomous system, a robot or a robotic process. Operators play a key role in the Oversight, corrective feedback and Data Labeling processes.",
            "metaphor": "",
            "updated": "2024-06-24"
        },
        {
            "language": "eng",
            "term": "Deployer",
            "definition": "A Deployer is an entity that intentionally brings an AI or robotic system into operation, overseeing its use and in most cases responsible for its actions. Deployer can be an individual, company, government agency, or non-profit organization. However, if someone uses a robotic system for personal, non-business purposes, they are not considered Deployers. Additionally, the Deployer may not be the same as a person or team developing and engineering such systems. Deployers are responsible for setting up proper Oversight processes and for implementing appropriate safety measures.",
            "metaphor": "",
            "updated": "2024-06-24"
        },
        {
            "language": "eng",
            "term": "Open Dataset",
            "definition": "Open data is data that can be freely accessed, used, shared and built-on by anyone, anywhere, for any purpose. This is the summary of the [full Open Definition](https://opendefinition.org/od/2.1/en/).",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Limited Access Dataset",
            "definition": "A Limited Access Dataset is a set of data that may be disclosed to an outside party without data subject authorization if certain conditions are met. Usually, the purpose of the disclosure may only be for research, security, public health or health care operations. Second, the organization/person receiving the Limited Access Dataset must sign a data use agreement with Data Controller.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Proprietary Dataset",
            "definition": "In the context of training the machine learning models, Proprietary Dataset is the fuel that can turn a commoditized workflow software into rich, competitively “defensible” engine. Proprietary Dataset could be created, aggregated, or both. There are different methods to build Proprietary Datasets, such as: scraping publicly available but scattered data, exploring partnerships with established entities, crowd-sourcing data collection and labeling, or collecting data from the use of the products/services.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Algorithm",
            "definition": "In computer science, an algorithm is a finite sequence of well-defined instructions that could be implemented in a computer program, typically to solve a class of problems or to perform a computation. An algorithm is often paired with words specifying the activity for which a set of rules has been designed.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Open Source",
            "definition": "Open-source software (OSS) is a type of computer software in which source code is released under a license where the copyright holder grants users the rights to study, change, and distribute the software to anyone and for any purpose. The main principle of Open Source is peer production, with products such as source code, blueprints, and documentation freely available to the public.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Proprietary Source",
            "definition": "Proprietary software is any software that is copyrighted and bears limits against use, distribution and modification that are imposed by its publisher, vendor or developer. In general, proprietary software doesn’t provide end users or subscribers with access to its source code.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Decision Space",
            "definition": "A decision space is the set of all possible decisions that the system can produce. Systems don’t make decisions like humans do, however they produce outputs that may directly influence the processes we use and the outcomes we rely upon. For instance, the decision space of a traffic light is a set of states that it exhibits, such as Green, Yellow, Red, blinking Yellow, and Not working at all.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Restricted Decision Space",
            "definition": "The Decision Space is called “Restricted”, when the set of AI model outputs is known and predefined. The above example of traffic light has a Restricted Decision Space.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Unrestricted Decision Space",
            "definition": "The Decision Space is called “Unrestricted”, when the set of AI model outputs is not limited, e.g. when either the type of output is not predicted or the output itself is generated by the model.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Machine Learning",
            "definition": "Machine learning is a subset of methods in Artificial Intelligence (AI), studying algorithms and statistical models to provide systems the ability to autonomously learn and improve from experience without being explicitly programmed.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Machine Learning Model",
            "definition": "A Machine Learning Model is the core component of a machine learning system. It’s a mathematical representation that captures the underlying structure of the data by generalizing from Training Datasets. Unlike algorithms based on instructions, Machine Learning Models learn patterns and can make predictions, perform classification, generate content, and aid in decision-making - based on new unseen inputs without explicit programming.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Modality",
            "definition": "In the context of AI, modality refers to the different ways in which interaction with AI systems is happening. It encompasses the various modes or channels through which AI systems understand data. Modalities can include text, speech, images, videos, tabular, and sensor data, among others. Handling multiple modalities is a crucial aspect of developing robust and versatile AI systems, as it enables them to comprehend and generate information across diverse formats.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Supervised Learning",
            "definition": "Supervised learning consists of mapping data to known labels which together are composed in a Training Data Set. This mapping process is done by human Subject-matter Experts provide during the Data Labeling process. Training the model means achieving sufficient accuracy of prediction for real-world examples. The testing of such models is performed using Test and Validation datasets.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Unsupervised Learning",
            "definition": "Unsupervised learning is where the input data is unlabeled and the system tries to learn the structure from that data automatically, without any human guidance. Anomaly detection, such as flagging unusual credit card transactions to prevent fraud, is an example of unsupervised learning.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Semi-supervised Learning",
            "definition": "Semi-supervised learning is often a combination of the first two approaches. That is, the system trains on partially labeled input data — usually a lot of unlabeled data and a little bit of labeled data. Facial recognition in photo services from Facebook and Google are real-world applications of this approach.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Reinforcement Learning",
            "definition": "Reinforcement learning occurs when a computer system receives data in a specific environment and then learns how to maximize its outcomes for particular criteria. Reinforcement learning differs from supervised learning in not needing labeled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Applications range from Robotics, personalized recommendations to drug development.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Transfer Learning",
            "definition": "Transfer learning is a machine learning technique where “knowledge” of a model trained on one task is applied to a different but related task. The idea behind transfer learning is that the features and patterns learned by a model while solving one specific set of task can be relevant and useful for solving another set of specific tasks. Instead of starting the learning process from scratch for the new type of tasks, transfer learning allows to bootstrap the model training process with the already acquired knowledge.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Fine-tuning",
            "definition": "Fine-tuning is one of the methods in Transfer Learning in the context of AI models. It refers to the process of taking a pre-trained model and further training it on a specific task or dataset to adapt it for that task. The key advantage of fine-tuning is that it allows developers to build effective models with relatively less data and computational resources than training from scratch. Finetuning has become a standard practice in many state-of-the-art NLP, audio-processing, and computer vision models.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Robotics",
            "definition": "Robotics is the intersection of science, engineering and technology that produces machines, called robots. A robot has three consistent characteristics: robots have a mechanical component that allows to complete tasks in the environment for which it’s designed. Robots require a source of power, typically electrical. To operate robots execute a computer program. Robots be of any form but some are made to resemble humans in appearance (called “androids”).",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Subject-matter Expert (SME)",
            "definition": "The term Subject-matter Expert or Domain Expert is frequently used in software development, and the term refers to the knowledge in the domains other than the software domain. Typically, SMEs have developed their expertise in their particular discipline over a long period of time and after a great deal of immersion in the topic.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Bias",
            "definition": "In Biased prediction (estimation, decision), the expected value of the result differs from the true underlying value being estimated. Bias is a statistical property and can be viewed as a systematic error introduced into measurement, sampling, or testing by selecting or encouraging one outcome or answer over the others.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Human-in-the-loop",
            "definition": "Human-in-the-loop (HITL) is a design pattern in AI that leverages both human and machine intelligence to bring meaningful automation scenarios into the real-world. The human-in-the-loop approach reframes an automation problem as a Human-Computer Interaction (HCI) design problem. With this approach AI systems are designed to augment or enhance the human capacity, serving as a tool to be exercised through human interaction.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Ethics",
            "definition": "A system of moral values and principles of conduct, governing an individual, a group or an AI system when it works as an autonomous subject of decision-making.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Open Ethics Vector",
            "definition": "Open Ethics Vector (OEV) reflects the priorities for values about how data-driven decisions are made. OEV allows to make sure that the value sets are aligned between AI systems and its users users. Disclosing prioritized value sets for applications and their components, making them open, can help end-users to learn which apps are best for them.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Open Ethics Label",
            "definition": "Open Ethics Label (OEL) is a set of user-facing graphical illustrations and textual descriptions of the digital product. It facilitates (ex-ante) understanding of the values and risks the product carries and translates a machine-readable Disclosure into a set of recognizable icons and marks. Additionally, icons can carry information about successful conformity assessment as a result of audit verification.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Personal Data",
            "definition": "Typically, it’s any data that can be used to distinguish or trace a living person (data subject). Definitions of Personal Data may differ depending on legislation.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Data Subject",
            "definition": "A data subject is an identifiable living person to whom a particular data item relates. A data subject may be given the ability to inquire about or remove their data according to a particular practice, standard, rule or regulation.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Data Controller",
            "definition": "Data Controller is the entity that takes ownership of personal data and determines how and by whom it is handled.",
            "metaphor": "",
            "updated": "2023-09-30"
        },
        {
            "language": "eng",
            "term": "Data Processor",
            "definition": "Data Processor is the entity that handles personal data on behalf of the controller. A data processor may have subprocessors.",
            "metaphor": "",
            "updated": "2023-09-30"
        }
    ]    
}
